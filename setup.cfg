[metadata]
name = spykfunc
description = A PySpark implementation of the BBP Functionalizer
long-description = file: README.rst
author = Fernando Pereira, Matthias Wolf
author-email = fernando.pereira@epfl.ch, matthias.wolf@epfl.ch
license = Blue Brain Project License
home-page = https://bbpteam.epfl.ch/project/issues/projects/FUNCZ
download-url = https://bbpgitlab.epfl.ch/hpc/circuit-building/spykfunc
description-file = README.rst

project-urls =
    Tracker = https://bbpteam.epfl.ch/project/issues/projects/FUNCZ
    Source = https://bbpgitlab.epfl.ch/hpc/circuit-building/spykfunc

# Add here all kinds of additional classifiers as defined under
# https://pypi.python.org/pypi?%3Aaction=list_classifiers
classifier =
    Development Status :: 4 - Beta
    Programming Language :: Python
    Programming Language :: Python :: 3
    Programming Language :: Python :: 3.9
    Programming Language :: Python :: 3.10
    Framework :: Spark
    Topic :: Scientific/Engineering
    License :: Other/Proprietary License

[options]
zip_safe = False
package_dir =
    = src
packages = find:
scripts =
    scripts/download_hadoop
    scripts/download_spark_startup
    scripts/sm_cluster
    scripts/sm_run
    scripts/sm_startup
    scripts/sm_shutdown
# bottleneck and numexpr normally installed via pandas, breaks when building containers.
install_requires =
    bottleneck
    funcsigs
    fz-td-recipe
    h5py
    hdfs
    jprops
    lxml
    morphio
    morphokit
    mpi4py
    libsonata
    numexpr
    numpy
    packaging
    pandas<2  # needs fix in pyspark
    pyarrow<11
    pyspark>=3,<3.5
setup_requires =
    cmake
    setuptools >= 50
    setuptools_scm

[options.packages.find]
include = spykfunc*, sparkmanager*, recipe*
where = src

[options.package_data]
spykfunc =
    data/*
    data/cluster/*

[options.entry_points]
console_scripts =
    functionalizer = spykfunc.commands:functionalize_parallel
    spykfunc = spykfunc.commands:functionalize
    parquet-compare = spykfunc.tools.compare:run
    parquet-compare-ns = spykfunc.tools.compare_nodesets:compare_nodesets
    parquet-coalesce = spykfunc.tools.coalesce:run

[build_ext]
inplace = 1

[bdist_wheel]
# Use this option if your package is pure-python
universal = 0

[devpi:upload]
# Options for the devpi: PyPI server and packaging tool
# VCS export must be deactivated since we are using setuptools-scm
no-vcs = 1
formats = bdist_wheel

[mypy-numpy.*]
ignore_missing_imports = True

[mypy-lxml.*]
ignore_missing_imports = True
